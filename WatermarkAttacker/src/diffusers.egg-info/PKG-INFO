Metadata-Version: 2.1
Name: diffusers
Version: 0.20.0.dev0
Summary: Diffusers
Home-page: https://github.com/huggingface/diffusers
Author: The HuggingFace team
Author-email: patrick@huggingface.co
License: Apache
Keywords: deep learning
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.7.0
Description-Content-Type: text/markdown
Requires-Dist: importlib_metadata
Requires-Dist: filelock
Requires-Dist: huggingface-hub>=0.13.2
Requires-Dist: numpy
Requires-Dist: regex!=2019.12.17
Requires-Dist: requests
Requires-Dist: safetensors>=0.3.1
Requires-Dist: Pillow
Provides-Extra: quality
Requires-Dist: urllib3<=2.0.0; extra == "quality"
Requires-Dist: black~=23.1; extra == "quality"
Requires-Dist: isort>=5.5.4; extra == "quality"
Requires-Dist: ruff==0.0.280; extra == "quality"
Requires-Dist: hf-doc-builder>=0.3.0; extra == "quality"
Provides-Extra: docs
Requires-Dist: hf-doc-builder>=0.3.0; extra == "docs"
Provides-Extra: training
Requires-Dist: accelerate>=0.11.0; extra == "training"
Requires-Dist: datasets; extra == "training"
Requires-Dist: protobuf<4,>=3.20.3; extra == "training"
Requires-Dist: tensorboard; extra == "training"
Requires-Dist: Jinja2; extra == "training"
Provides-Extra: test
Requires-Dist: compel==0.1.8; extra == "test"
Requires-Dist: datasets; extra == "test"
Requires-Dist: Jinja2; extra == "test"
Requires-Dist: invisible-watermark>=0.2.0; extra == "test"
Requires-Dist: k-diffusion>=0.0.12; extra == "test"
Requires-Dist: librosa; extra == "test"
Requires-Dist: omegaconf; extra == "test"
Requires-Dist: parameterized; extra == "test"
Requires-Dist: pytest; extra == "test"
Requires-Dist: pytest-timeout; extra == "test"
Requires-Dist: pytest-xdist; extra == "test"
Requires-Dist: requests-mock==1.10.0; extra == "test"
Requires-Dist: safetensors>=0.3.1; extra == "test"
Requires-Dist: sentencepiece!=0.1.92,>=0.1.91; extra == "test"
Requires-Dist: scipy; extra == "test"
Requires-Dist: torchvision; extra == "test"
Requires-Dist: transformers>=4.25.1; extra == "test"
Provides-Extra: torch
Requires-Dist: torch>=1.4; extra == "torch"
Requires-Dist: accelerate>=0.11.0; extra == "torch"
Provides-Extra: flax
Provides-Extra: dev
Requires-Dist: urllib3<=2.0.0; extra == "dev"
Requires-Dist: black~=23.1; extra == "dev"
Requires-Dist: isort>=5.5.4; extra == "dev"
Requires-Dist: ruff==0.0.280; extra == "dev"
Requires-Dist: hf-doc-builder>=0.3.0; extra == "dev"
Requires-Dist: compel==0.1.8; extra == "dev"
Requires-Dist: datasets; extra == "dev"
Requires-Dist: Jinja2; extra == "dev"
Requires-Dist: invisible-watermark>=0.2.0; extra == "dev"
Requires-Dist: k-diffusion>=0.0.12; extra == "dev"
Requires-Dist: librosa; extra == "dev"
Requires-Dist: omegaconf; extra == "dev"
Requires-Dist: parameterized; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Requires-Dist: pytest-timeout; extra == "dev"
Requires-Dist: pytest-xdist; extra == "dev"
Requires-Dist: requests-mock==1.10.0; extra == "dev"
Requires-Dist: safetensors>=0.3.1; extra == "dev"
Requires-Dist: sentencepiece!=0.1.92,>=0.1.91; extra == "dev"
Requires-Dist: scipy; extra == "dev"
Requires-Dist: torchvision; extra == "dev"
Requires-Dist: transformers>=4.25.1; extra == "dev"
Requires-Dist: accelerate>=0.11.0; extra == "dev"
Requires-Dist: datasets; extra == "dev"
Requires-Dist: protobuf<4,>=3.20.3; extra == "dev"
Requires-Dist: tensorboard; extra == "dev"
Requires-Dist: Jinja2; extra == "dev"
Requires-Dist: hf-doc-builder>=0.3.0; extra == "dev"
Requires-Dist: torch>=1.4; extra == "dev"
Requires-Dist: accelerate>=0.11.0; extra == "dev"

# WatermarkAttacker

### **Welcome to contribute to this project!**

This repository contains the code for the paper [Invisible Image Watermarks Are Provably Removable Using Generative AI](https://arxiv.org/abs/2306.01953).

We propose a family of **regeneration attacks** to remove invisible image watermarks. The attack method effectively removes invisible watermarks. 

Our attack first maps the watermarked image to its embedding, which is another representation of the image. Then the embedding is noised to destruct the watermark. After that, a regeneration algorithm reconstructs the image from the noisy embedding. As shown in the figure below:

![demo](./fig/demo.png)



<!-- If you find this repository useful, please cite our paper:

```
@article{zhao2023provable,
  title={Provable Robust Watermarking for AI-Generated Text},
  author={Zhao, Xuandong and Ananth, Prabhanjan and Li, Lei and Wang, Yu-Xiang},
  journal={arXiv preprint arXiv:2306.17439},
  year={2023}
}
``` -->


## Example

First, install the dependencies:

```bash
pip install -r requirements.txt
```

Then, run the following command to install modified [diffusers](https://github.com/huggingface/diffusers)

```bash
pip install -e .
```

Then you can try the demo in `demo.ipynb`.

This demo attacks [invisible-watermark](https://github.com/ShieldMnt/invisible-watermark) which is used in [stable diffusion](https://github.com/Stability-AI/stablediffusion).

## How it works?

In short, our method can be described using the following **equation (1)**

$$
\begin{equation}
\hat{x} =  \underbrace{\mathcal{A}\Big( \overbrace{\phi(x_w) + \mathcal{N}(0,\sigma^2 I_d)}^{\text{destructive}}\Big)}_{\text{constructive}},
\end{equation}
$$

where $x_w$ is the watermarked image, $\phi$ is an embedding function, $\mathcal{N}$ is a Gaussian distribution that adds noise to the embedding, and $\mathcal{A}$ is a reconstruction algorithm that takes the noisy embedding of the image and tries to construct the original image.

The embedding function $\phi$ and the reconstruction algorithm $\mathcal{A}$ can be instantiated with many algorithms.

**Here let's look at how [Stable Diffusion](https://github.com/CompVis/stable-diffusion) can instantiate our algorithm** (see this [blog](https://huggingface.co/blog/stable_diffusion) for more information on Stable Diffusion).

![img](https://ommer-lab.com/wp-content/uploads/2022/08/article-Figure3-1.png)

The above figure shows the architecture of Stable Diffusion.

The destructive process in our algorithm corresponds to adding noise to the image until a certain time step $t$. To do this, Stable Diffusion first maps the image from the pixel space to a latent space using its VAE encoder $\mathcal{E}$, and then adds noise to the latent space using a diffusion process, which is defined in the following **equation (2)**

$$
\begin{equation}
z_t=\overbrace{\sqrt{\alpha(t)}\mathcal{E}(x_w)}^{\phi(x_w)}+\mathcal{N}(0,\overbrace{(1-\alpha(t))}^{\sigma^2}I_d),
\end{equation}
$$

where $\alpha(t)$ is a function that controls the amount of noise added at time step $t$. By comparing equations (1) and (2), we can see that the embedding function $\phi$ is the scaled VAE encoder $\sqrt{\alpha(t)}\mathcal{E}$.

After obtaining the noised representation $z_t$, we denoise it using Stable Diffusion to reconstruct the image, which corresponds to $\mathcal{A}$ in equation (1).
